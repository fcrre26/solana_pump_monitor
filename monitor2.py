#!/usr/bin/env python3
import os
import sys
import time
import json
import logging
import requests
import urllib3
import traceback
from datetime import datetime, timezone, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed
from wcferry import Wcf
from queue import Queue
from threading import Thread

# ç¦ç”¨SSLè­¦å‘Š
urllib3.disable_warnings()

def format_number(number):
    """å°†æ•°å­—æ ¼å¼åŒ–ä¸ºK/M/Bæ ¼å¼"""
    if number >= 1_000_000_000:
        return f"{number/1_000_000_000:.2f}B"
    elif number >= 1_000_000:
        return f"{number/1_000_000:.2f}M"
    elif number >= 1_000:
        return f"{number/1_000:.2f}K"
    return f"{number:.2f}"

class TokenMonitor:
    def __init__(self):
        try:
            self.config_file = os.path.expanduser("~/.solana_pump.cfg")
            self.rpc_file = os.path.expanduser("~/.solana_pump.rpc")
            self.watch_file = os.path.expanduser("~/.solana_pump/watch_addresses.json")
            self.config = self.load_config()
            self.api_keys = self.config.get('api_keys', [])
            self.current_key = 0
            self.request_counts = {}
            self.last_reset = {}
            self.wcf = None
            self.watch_addresses = self.load_watch_addresses()
            self.init_wcf()
            
            # åˆå§‹åŒ–ä»£ç†é…ç½®
            self.proxy_config = {
                'ip': None,
                'port': None,
                'username': None,
                'password': None,
                'enabled': False
            }
            # ä»é…ç½®æ–‡ä»¶åŠ è½½ä»£ç†è®¾ç½®
            if 'proxy' in self.config:
                self.proxy_config.update(self.config['proxy'])
            
            # åˆå§‹åŒ–APIå¯†é’¥è®¡æ•°å™¨
            for key in self.api_keys:
                if key.strip():
                    self.request_counts[key] = 0
                    self.last_reset[key] = time.time()

            # æ·»åŠ ç¼“å­˜
            self.cache = {
                'token_info': {},
                'creator_history': {},
                'fund_flow': {}
            }
            self.cache_expire = {
                'token_info': 300,      # 5åˆ†é’Ÿ
                'creator_history': 1800, # 30åˆ†é’Ÿ
                'fund_flow': 600        # 10åˆ†é’Ÿ
            }
            
            # å¢åŠ å¹¶è¡Œå¤„ç†é…ç½®
            self.parallel_requests = 20  # å¢åŠ åˆ°20ä¸ªå¹¶è¡Œè¯·æ±‚
            self.block_batch_size = 100  # æ¯æ‰¹å¤„ç†100ä¸ªåŒºå—
            self.worker_threads = 20     # å¢åŠ å·¥ä½œçº¿ç¨‹
            
            # åˆ›å»ºå¤„ç†é˜Ÿåˆ—(å¢åŠ é˜Ÿåˆ—å¤§å°)
            self.tx_queue = Queue(maxsize=1000)
            self.result_queue = Queue(maxsize=1000)
            
            # åˆ›å»ºçº¿ç¨‹æ± 
            self.executor = ThreadPoolExecutor(max_workers=self.worker_threads)
            
            # æ·»åŠ ç›‘æ§æŒ‡æ ‡
            self.metrics = {
                'processed_blocks': 0,
                'processed_txs': 0,
                'missed_blocks': set(),
                'last_process_time': time.time(),
                'processing_delays': []
            }
            
            # å¯åŠ¨ç›‘æ§çº¿ç¨‹
            Thread(target=self.monitor_metrics, daemon=True).start()
            
            # åˆå§‹åŒ–RPCèŠ‚ç‚¹ç®¡ç†
            self.init_rpc_nodes()
            
            # åˆå§‹åŒ–ä»£ç†IPæ± 
            self.proxy_pool = []
            self.current_proxy = 0
            
            # å¯åŠ¨å¤„ç†çº¿ç¨‹
            self.start_worker_threads()
            
            logging.info("TokenMonitoråˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logging.error(f"TokenMonitoråˆå§‹åŒ–å¤±è´¥: {str(e)}")
            logging.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            raise

    def init_rpc_nodes(self):
        """åˆå§‹åŒ–RPCèŠ‚ç‚¹é…ç½®"""
        self.rpc_nodes = {
            # å®˜æ–¹èŠ‚ç‚¹
            "https://api.mainnet-beta.solana.com": {"weight": 1, "fails": 0, "last_used": 0},
            "https://api.metaplex.solana.com": {"weight": 1, "fails": 0, "last_used": 0},
            
            # Project SerumèŠ‚ç‚¹
            "https://solana-api.projectserum.com": {"weight": 1, "fails": 0, "last_used": 0},
            
            # GenesysGoèŠ‚ç‚¹
            "https://ssc-dao.genesysgo.net": {"weight": 1, "fails": 0, "last_used": 0},
            
            # AnkrèŠ‚ç‚¹
            "https://rpc.ankr.com/solana": {"weight": 1, "fails": 0, "last_used": 0},
            
            # æ·»åŠ æ›´å¤šå¤‡ç”¨èŠ‚ç‚¹
            "https://mainnet.rpcpool.com": {"weight": 2, "fails": 0, "last_used": 0},
            "https://api.mainnet.rpcpool.com": {"weight": 2, "fails": 0, "last_used": 0},
        }
        
        # ä¼˜åŒ–è¯·æ±‚é™åˆ¶
        self.request_limits = {
            "default": {
                "requests_per_second": 10,  # å¢åŠ æ¯ç§’è¯·æ±‚æ•°
                "min_interval": 0.1,     # å‡å°‘æœ€å°é—´éš”
                "burst_wait": 5,         # å‡å°‘ç­‰å¾…æ—¶é—´
                "current_requests": 0,
                "last_request": 0
            }
        }
        
        # ä¸ºæ¯ä¸ªèŠ‚ç‚¹åˆå§‹åŒ–è¯·æ±‚è®¡æ•°å™¨
        for node in self.rpc_nodes:
            self.request_limits[node] = self.request_limits["default"].copy()
        
        self.current_rpc = None
        self.rpc_switch_interval = 60  # 60ç§’åˆ‡æ¢ä¸€æ¬¡èŠ‚ç‚¹
        self.last_rpc_switch = 0
        self.max_fails = 3  # æœ€å¤§å¤±è´¥æ¬¡æ•°

    def load_config(self):
        try:
            with open(self.config_file) as f:
                config = json.load(f)
                logging.info(f"æˆåŠŸåŠ è½½é…ç½®æ–‡ä»¶: {self.config_file}")
                return config
        except Exception as e:
            logging.error(f"åŠ è½½é…ç½®å¤±è´¥: {str(e)}")
            logging.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return {"api_keys": [], "serverchan": {"keys": []}, "wcf": {"groups": []}}

    def load_watch_addresses(self):
        try:
            with open(self.watch_file) as f:
                data = json.load(f)
                addresses = {addr['address']: addr['note'] for addr in data.get('addresses', [])}
                logging.info(f"æˆåŠŸåŠ è½½å…³æ³¨åœ°å€: {len(addresses)}ä¸ª")
                return addresses
        except Exception as e:
            logging.error(f"åŠ è½½å…³æ³¨åœ°å€å¤±è´¥: {str(e)}")
            logging.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return {}

    def init_wcf(self):
        if self.config['wcf']['groups']:
            try:
                self.wcf = Wcf()
                logging.info("WeChatFerryåˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                logging.error(f"WeChatFerryåˆå§‹åŒ–å¤±è´¥: {str(e)}")
                logging.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
                self.wcf = None

    def get_next_api_key(self):
        """è·å–ä¸‹ä¸€ä¸ªå¯ç”¨çš„APIå¯†é’¥"""
        try:
            now = time.time()
            for key in self.api_keys:
                if not key.strip():
                    continue
                    
                if now - self.last_reset[key] >= 60:
                    self.request_counts[key] = 0
                    self.last_reset[key] = now
                
                if self.request_counts[key] < 100:
                    self.request_counts[key] += 1
                    return key
            
            raise Exception("æ‰€æœ‰APIå¯†é’¥å·²è¾¾åˆ°é™åˆ¶")
        except Exception as e:
            logging.error(f"è·å–APIå¯†é’¥å¤±è´¥: {str(e)}")
            logging.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            raise

    def check_rate_limit(self, node):
        """æ£€æŸ¥æ˜¯å¦è¶…å‡ºè¯·æ±‚é™åˆ¶"""
        current_time = time.time()
        limits = self.request_limits.get(node, self.request_limits["default"])
        
        # æ£€æŸ¥æœ€å°é—´éš”
        if current_time - limits["last_request"] < limits["min_interval"]:
            time.sleep(limits["min_interval"])
        
        # æ£€æŸ¥æ¯ç§’è¯·æ±‚æ•°
        if limits["current_requests"] >= limits["requests_per_second"]:
            sleep_time = 1.0 - (current_time - limits["last_request"])
            if sleep_time > 0:
                time.sleep(sleep_time)
            limits["current_requests"] = 0
        
        limits["current_requests"] += 1
        limits["last_request"] = current_time
        return True

    def get_next_proxy(self):
        """è·å–ä¸‹ä¸€ä¸ªä»£ç†é…ç½®ï¼ˆæ¯æ¬¡è¯·æ±‚æ¢ä¸€ä¸ªIPï¼‰"""
        if not self.proxy_config['enabled']:
            return None
            
        # è¿™é‡Œå‡è®¾æ¯æ¬¡è°ƒç”¨éƒ½ä¼šå¾—åˆ°ä¸€ä¸ªæ–°çš„åŠ¨æ€IP
        proxy_url = f"http://{self.proxy_config['username']}:{self.proxy_config['password']}@{self.proxy_config['ip']}:{self.proxy_config['port']}"
        
        return {
            "http": proxy_url,
            "https": proxy_url
        }

    def parallel_rpc_request(self, method, params=None):
        """å¹¶è¡Œå‘é€RPCè¯·æ±‚åˆ°å¤šä¸ªèŠ‚ç‚¹"""
        futures = []
        
        with ThreadPoolExecutor(max_workers=self.parallel_requests) as executor:
            # åŒæ—¶å‘èµ·å¤šä¸ªè¯·æ±‚
            for _ in range(self.parallel_requests):
                rpc = self.get_best_rpc()
                proxy = self.get_next_proxy()  # æ¯ä¸ªè¯·æ±‚ä½¿ç”¨æ–°çš„IP
                
                future = executor.submit(
                    self.make_rpc_request,
                    rpc,
                    method,
                    params,
                    proxy
                )
                futures.append(future)
            
            # ç­‰å¾…ç¬¬ä¸€ä¸ªæˆåŠŸçš„ç»“æœ
            for future in as_completed(futures):
                try:
                    result = future.result()
                    if result and result.status_code == 200:
                        return result
                except Exception as e:
                    continue
        
        return None

    def make_rpc_request(self, node, method, params=None, proxy=None):
        """å‘é€RPCè¯·æ±‚ï¼Œæ”¯æŒæŒ‡å®šä»£ç†"""
        try:
            self.check_rate_limit(node)
            
            response = requests.post(
                node,
                json={
                    "jsonrpc": "2.0",
                    "id": 1,
                    "method": method,
                    "params": params or []
                },
                proxies=proxy,
                timeout=3,
                verify=False
            )
            
            if response.status_code == 429:
                logging.warning(f"èŠ‚ç‚¹ {node} è§¦å‘è¯·æ±‚é™åˆ¶")
                time.sleep(self.request_limits[node]["burst_wait"])
                return None
                
            return response
            
        except Exception as e:
            logging.warning(f"è¯·æ±‚å¤±è´¥: {str(e)}")
            return None

    def get_best_rpc(self):
        """è·å–æœ€ä½³RPCèŠ‚ç‚¹"""
        current_time = time.time()
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ‡æ¢èŠ‚ç‚¹
        if (self.current_rpc and 
            self.rpc_nodes[self.current_rpc]["fails"] < self.max_fails and 
            current_time - self.last_rpc_switch < self.rpc_switch_interval):
            return self.current_rpc
        
        # æŒ‰æƒé‡å’Œå¤±è´¥æ¬¡æ•°æ’åºèŠ‚ç‚¹
        available_nodes = sorted(
            self.rpc_nodes.items(),
            key=lambda x: (x[1]["fails"], -x[1]["weight"], x[1]["last_used"])
        )
        
        # æµ‹è¯•èŠ‚ç‚¹ç›´åˆ°æ‰¾åˆ°å¯ç”¨çš„
        for node, info in available_nodes:
            try:
                logging.info(f"æµ‹è¯•RPCèŠ‚ç‚¹: {node}")
                response = self.make_rpc_request(node, "getHealth")
                
                if response and response.status_code == 200:
                    # æ›´æ–°èŠ‚ç‚¹çŠ¶æ€
                    self.rpc_nodes[node]["fails"] = 0
                    self.rpc_nodes[node]["last_used"] = current_time
                    self.current_rpc = node
                    self.last_rpc_switch = current_time
                    
                    # æµ‹è¯•å»¶è¿Ÿ
                    start_time = time.time()
                    self.make_rpc_request(node, "getHealth")
                    latency = (time.time() - start_time) * 1000
                    
                    # æ ¹æ®å»¶è¿Ÿè°ƒæ•´æƒé‡
                    if latency < 100:
                        self.rpc_nodes[node]["weight"] += 0.1
                    elif latency > 500:
                        self.rpc_nodes[node]["weight"] = max(0.1, self.rpc_nodes[node]["weight"] - 0.1)
                    
                    logging.info(f"ä½¿ç”¨RPCèŠ‚ç‚¹: {node} (å»¶è¿Ÿ: {latency:.1f}ms, æƒé‡: {self.rpc_nodes[node]['weight']:.1f})")
                    return node
                
            except Exception as e:
                logging.warning(f"èŠ‚ç‚¹ {node} æµ‹è¯•å¤±è´¥: {str(e)}")
                self.rpc_nodes[node]["fails"] += 1
                continue
        
        # å¦‚æœæ‰€æœ‰èŠ‚ç‚¹éƒ½å¤±è´¥ï¼Œé‡ç½®å¤±è´¥è®¡æ•°å¹¶è¿”å›é»˜è®¤èŠ‚ç‚¹
        for node in self.rpc_nodes:
            self.rpc_nodes[node]["fails"] = 0
        
        default_node = "https://api.mainnet-beta.solana.com"
        logging.warning(f"æ‰€æœ‰èŠ‚ç‚¹ä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤èŠ‚ç‚¹: {default_node}")
        return default_node

    def handle_rpc_error(self, node, error):
        """å¤„ç†RPCé”™è¯¯"""
        if node in self.rpc_nodes:
            self.rpc_nodes[node]["fails"] += 1
            if self.rpc_nodes[node]["fails"] >= self.max_fails:
                logging.warning(f"èŠ‚ç‚¹ {node} å¤±è´¥æ¬¡æ•°è¿‡å¤šï¼Œå°†åœ¨ä¸‹æ¬¡åˆ‡æ¢èŠ‚ç‚¹")
                self.last_rpc_switch = 0  # å¼ºåˆ¶ä¸‹æ¬¡åˆ‡æ¢èŠ‚ç‚¹

    def fetch_token_info(self, mint):
        """è·å–ä»£å¸è¯¦ç»†ä¿¡æ¯"""
        try:
            headers = {"X-API-KEY": self.get_next_api_key()}
            
            # è·å–åŸºæœ¬ä¿¡æ¯
            url = f"https://public-api.birdeye.so/public/token_metadata?address={mint}"
            resp = requests.get(url, headers=headers, timeout=5)
            data = resp.json()
            
            if data.get("success"):
                token_data = data["data"]
                
                # è·å–æŒæœ‰äººä¿¡æ¯
                holders_url = f"https://public-api.birdeye.so/public/token_holders?address={mint}"
                holders_resp = requests.get(holders_url, headers=headers, timeout=5)
                holders_data = holders_resp.json().get("data", [])
                
                # è®¡ç®—æŒæœ‰äººé›†ä¸­åº¦
                total_supply = float(token_data.get("supply", 0))
                holder_concentration = 0
                if holders_data and total_supply > 0:
                    top_10_holdings = sum(float(h.get("amount", 0)) for h in holders_data[:10])
                    holder_concentration = (top_10_holdings / total_supply) * 100
                
                token_info = {
                    "name": token_data.get("name", "Unknown"),
                    "symbol": token_data.get("symbol", "Unknown"),
                    "price": float(token_data.get("price", 0)),
                    "supply": float(token_data.get("supply", 0)),
                    "market_cap": float(token_data.get("price", 0)) * float(token_data.get("supply", 0)),
                    "liquidity": float(token_data.get("liquidity", 0)),
                    "holder_count": len(holders_data),
                    "holder_concentration": holder_concentration,
                    "verified": token_data.get("verified", False)
                }
                logging.info(f"è·å–ä»£å¸ä¿¡æ¯æˆåŠŸ: {json.dumps(token_info, indent=2)}")
                return token_info
        except Exception as e:
            logging.error(f"è·å–ä»£å¸ä¿¡æ¯å¤±è´¥: {str(e)}")
            logging.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        
        return {
            "name": "Unknown",
            "symbol": "Unknown",
            "price": 0,
            "supply": 0,
            "market_cap": 0,
            "liquidity": 0,
            "holder_count": 0,
            "holder_concentration": 0,
            "verified": False
        }

    def analyze_creator_history(self, creator):
        """åˆ†æåˆ›å»ºè€…å†å²è®°å½•"""
        try:
            # æ£€æŸ¥ç¼“å­˜
            if creator in self.cache['creator_history']:
                cache_data = self.cache['creator_history'][creator]
                if time.time() - cache_data['timestamp'] < self.cache_expire['creator_history']:
                    logging.info(f"ä½¿ç”¨ç¼“å­˜çš„åˆ›å»ºè€…å†å²: {creator}")
                    return cache_data['history']
            
            headers = {"X-API-KEY": self.get_next_api_key()}
            url = f"https://public-api.birdeye.so/public/address_nft_mints?address={creator}"
            resp = requests.get(url, headers=headers, timeout=5)
            data = resp.json()
            
            if data.get("success"):
                history = []
                for tx in data["data"]:
                    if "mint" in tx:
                        token_info = self.fetch_token_info(tx["mint"])
                        
                        # è·å–å†å²æœ€é«˜å¸‚å€¼
                        max_market_cap = 0
                        try:
                            history_url = f"https://public-api.birdeye.so/public/token_price_history?address={tx['mint']}"
                            history_resp = requests.get(history_url, headers=headers, timeout=5)
                            if history_resp.status_code == 200:
                                price_history = history_resp.json().get("data", [])
                                if price_history:
                                    max_price = max(float(p.get("value", 0)) for p in price_history)
                                    max_market_cap = max_price * token_info["supply"]
                        except Exception as e:
                            logging.warning(f"è·å–ä»·æ ¼å†å²å¤±è´¥: {str(e)}")
                        
                        history.append({
                            "mint": tx["mint"],
                            "timestamp": tx["timestamp"],
                            "current_market_cap": token_info["market_cap"],
                            "max_market_cap": max_market_cap,
                            "liquidity": token_info["liquidity"],
                            "holder_count": token_info["holder_count"],
                            "holder_concentration": token_info["holder_concentration"],
                            "status": "æ´»è·ƒ" if token_info["market_cap"] > 0 else "å·²é€€å‡º"
                        })
                
                # ç¼“å­˜ç»“æœ
                self.cache['creator_history'][creator] = {
                    'timestamp': time.time(),
                    'history': history
                }
                logging.info(f"åˆ†æåˆ›å»ºè€…å†å²æˆåŠŸ: {creator}, å‘ç° {len(history)} ä¸ªä»£å¸")
                return history
        except Exception as e:
            logging.error(f"åˆ†æåˆ›å»ºè€…å†å²å¤±è´¥: {str(e)}")
            logging.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        
        return []

    def analyze_creator_relations(self, creator):
        """åˆ†æåˆ›å»ºè€…åœ°å€å…³è”æ€§"""
        try:
            related_addresses = set()
            relations = []
            watch_hits = []
            high_value_relations = []
            
            # 1. åˆ†æè½¬è´¦å†å²
            headers = {"X-API-KEY": self.get_next_api_key()}
            url = f"https://public-api.birdeye.so/public/address_activity?address={creator}"
            resp = requests.get(url, headers=headers, timeout=5)
            data = resp.json()
            
            if data.get("success"):
                # è®°å½•åœ°å€é¦–æ¬¡äº¤æ˜“æ—¶é—´
                first_tx_time = float('inf')
                for tx in data["data"]:
                    first_tx_time = min(first_tx_time, tx.get("timestamp", float('inf')))
                    
                    # è®°å½•æ‰€æœ‰äº¤äº’è¿‡çš„åœ°å€
                    if tx.get("from") and tx["from"] != creator:
                        related_addresses.add(tx["from"])
                        if tx["from"] in self.watch_addresses:
                            watch_hits.append({
                                'address': tx["from"],
                                'note': self.watch_addresses[tx["from"]],
                                'type': 'transfer_from',
                                'amount': tx.get("amount", 0),
                                'timestamp': tx["timestamp"]
                            })
                            
                    if tx.get("to") and tx["to"] != creator:
                        related_addresses.add(tx["to"])
                        if tx["to"] in self.watch_addresses:
                            watch_hits.append({
                                'address': tx["to"],
                                'note': self.watch_addresses[tx["to"]],
                                'type': 'transfer_to',
                                'amount': tx.get("amount", 0),
                                'timestamp': tx["timestamp"]
                            })
                        
                    # ç‰¹åˆ«å…³æ³¨å¤§é¢è½¬è´¦
                    if tx.get("amount", 0) > 1:  # 1 SOLä»¥ä¸Šçš„è½¬è´¦
                        relations.append({
                            "address": tx["to"] if tx["from"] == creator else tx["from"],
                            "type": "transfer",
                            "amount": tx["amount"],
                            "timestamp": tx["timestamp"]
                        })
                
                # è®¡ç®—é’±åŒ…å¹´é¾„ï¼ˆå¤©ï¼‰
                wallet_age = (time.time() - first_tx_time) / (24 * 3600) if first_tx_time != float('inf') else 0
            
            # 2. æ·±åº¦åˆ†æå…³è”åœ°å€
            for address in related_addresses:
                # åˆ†æä»£å¸åˆ›å»ºå†å²
                token_history = self.analyze_creator_history(address)
                if token_history:
                    # æ‰¾å‡ºé«˜ä»·å€¼ä»£å¸ï¼ˆæœ€é«˜å¸‚å€¼è¶…è¿‡1äº¿ç¾å…ƒï¼‰
                    high_value_tokens = [t for t in token_history 
                                       if t["max_market_cap"] > 100_000_000]
                    
                    if high_value_tokens:
                        high_value_relations.append({
                            "address": address,
                            "tokens": high_value_tokens,
                            "total_created": len(token_history)
                        })
                    
                    relations.append({
                        "address": address,
                        "type": "token_creator",
                        "tokens": len(token_history),
                        "success_rate": sum(1 for t in token_history if t["status"] == "æ´»è·ƒ") / len(token_history),
                        "high_value_tokens": len(high_value_tokens)
                    })
            
            # 3. åˆ†æå…±åŒç­¾åè€…
            with ThreadPoolExecutor(max_workers=3) as executor:
                futures = []
                for address in related_addresses:
                    futures.append(executor.submit(self._analyze_cosigners, 
                                                address, creator))
                
                for future in futures:
                    try:
                        result = future.result()
                        if result:
                            relations.extend(result)
                    except Exception as e:
                        logging.warning(f"åˆ†æå…±åŒç­¾åè€…å¤±è´¥: {str(e)}")
                        continue
            
            result = {
                "wallet_age": wallet_age,
                "is_new_wallet": wallet_age < 7,  # å°äº7å¤©è§†ä¸ºæ–°é’±åŒ…
                "related_addresses": list(related_addresses),
                "relations": relations,
                "watch_hits": watch_hits,
                "high_value_relations": high_value_relations,
                "risk_score": self.calculate_risk_score(relations, wallet_age)
            }
            logging.info(f"åˆ†æåˆ›å»ºè€…å…³è”æ€§æˆåŠŸ: {creator}")
            return result
        except Exception as e:
            logging.error(f"åˆ†æåˆ›å»ºè€…å…³è”æ€§å¤±è´¥: {str(e)}")
            logging.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return {
                "wallet_age": 0,
                "is_new_wallet": True,
                "related_addresses": [],
                "relations": [],
                "watch_hits": [],
                "high_value_relations": [],
                "risk_score": 0
            }

    def _analyze_cosigners(self, address, creator):
        """åˆ†æå…±åŒç­¾åè€…ï¼ˆè¾…åŠ©å‡½æ•°ï¼‰"""
        try:
            tx_url = f"https://public-api.solscan.io/account/transactions?account={address}"
            tx_resp = requests.get(tx_url, timeout=5)
            tx_data = tx_resp.json()
            
            cosigner_relations = []
            for tx in tx_data[:100]:  # åªçœ‹æœ€è¿‘100ç¬”äº¤æ˜“
                if creator in tx.get("signatures", []):
                    cosigner_relations.append({
                        "address": address,
                        "type": "co_signer",
                        "tx_hash": tx["signature"],
                        "timestamp": tx["blockTime"]
                    })
            return cosigner_relations
        except Exception as e:
            logging.warning(f"åˆ†æå…±åŒç­¾åè€…å¤±è´¥: {str(e)}")
            return []

    def calculate_risk_score(self, relations, wallet_age):
        """è®¡ç®—é£é™©åˆ†æ•°"""
        try:
            score = 0
            
            # 1. é’±åŒ…å¹´é¾„è¯„åˆ† (0-25åˆ†)
            if wallet_age < 1:  # å°äº1å¤©
                score += 25
            elif wallet_age < 7:  # å°äº7å¤©
                score += 15
            elif wallet_age < 30:  # å°äº30å¤©
                score += 5
            
            # 2. å…³è”åœ°å€è¯„åˆ† (0-25åˆ†)
            unique_addresses = len(set(r["address"] for r in relations))
            if unique_addresses > 20:
                score += 25
            elif unique_addresses > 10:
                score += 15
            elif unique_addresses > 5:
                score += 5
            
            # 3. ä»£å¸åˆ›å»ºè€…åˆ†æ (0-25åˆ†)
            token_creators = [r for r in relations if r["type"] == "token_creator"]
            if token_creators:
                # è®¡ç®—å¹³å‡æˆåŠŸç‡
                avg_success = sum(t["success_rate"] for t in token_creators) / len(token_creators)
                # è®¡ç®—é«˜ä»·å€¼ä»£å¸æ•°é‡
                high_value_count = sum(t.get("high_value_tokens", 0) for t in token_creators)
                
                if avg_success < 0.2:  # æˆåŠŸç‡ä½äº20%
                    score += 25
                elif avg_success < 0.4:  # æˆåŠŸç‡ä½äº40%
                    score += 15
                elif avg_success < 0.6:  # æˆåŠŸç‡ä½äº60%
                    score += 5
                
                # å¦‚æœæœ‰é«˜ä»·å€¼ä»£å¸å†å²ï¼Œé™ä½é£é™©åˆ†æ•°
                if high_value_count > 0:
                    score = max(0, score - 15)
            
            # 4. äº¤æ˜“è¡Œä¸ºè¯„åˆ† (0-25åˆ†)
            large_transfers = [r for r in relations if r["type"] == "transfer" and r["amount"] > 10]
            suspicious_patterns = len([t for t in large_transfers if any(
                abs(t["timestamp"] - other["timestamp"]) < 300  # 5åˆ†é’Ÿå†…
                for other in large_transfers
                if t != other
            )])
            
            if suspicious_patterns > 5:
                score += 25
            elif suspicious_patterns > 2:
                score += 15
            elif suspicious_patterns > 0:
                score += 5
            
            return min(score, 100)  # æœ€é«˜100åˆ†
        except Exception as e:
            logging.error(f"è®¡ç®—é£é™©åˆ†æ•°å¤±è´¥: {str(e)}")
            logging.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return 0

    def format_alert_message(self, data):
        """æ ¼å¼åŒ–è­¦æŠ¥æ¶ˆæ¯"""
        try:
            creator = data["creator"]
            mint = data["mint"]
            token_info = data["token_info"]
            history = data["history"]
            relations = data["relations"]
            
            msg = [
                "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” ï¿½ï¿½ å‘ç°æ–°ä»£å¸ (UTC+8) â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“",
                "",
                "ğŸ“‹ åŸºæœ¬ä¿¡æ¯",
                "â”£â” ä»£å¸åœ°å€:",
                f"{mint}",
                "",
                f"â”£â” åˆ›å»ºè€…: {creator}",
                f"â”—â” é’±åŒ…çŠ¶æ€: {'ğŸ†• æ–°é’±åŒ…' if relations['is_new_wallet'] else 'ğŸ“… è€é’±åŒ…'} | é’±åŒ…å¹´é¾„: {relations['wallet_age']:.1f} å¤©",
                "",
                "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” ğŸ’° ä»£å¸æ•°æ® â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“",
                f"â”ƒ ä»£å¸åç§°: {token_info['name']:<15} | ä»£å¸ç¬¦å·: {token_info['symbol']:<8} | è®¤è¯çŠ¶æ€: {'âœ… å·²è®¤è¯' if token_info['verified'] else 'âŒ æœªè®¤è¯'} â”ƒ",
                f"â”ƒ åˆå§‹å¸‚å€¼: ${format_number(token_info['market_cap']):<12} | ä»£å¸ä¾›åº”é‡: {format_number(token_info['supply']):<8} | å•ä»·: ${token_info['price']:.8f} â”ƒ",
                f"â”ƒ æµåŠ¨æ€§: {token_info['liquidity']:.2f} SOL{' '*8} | æŒæœ‰äººæ•°: {token_info['holder_count']:<8} | å‰10æŒæœ‰æ¯”: {token_info['holder_concentration']:.1f}% â”ƒ",
                "â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›",
                ""
            ]

            # æ·»åŠ èµ„é‡‘è¿½è¸ªä¿¡æ¯
            if relations['related_addresses']:
                total_transfer = sum(r['amount'] for r in relations['relations'] if r['type'] == 'transfer')
                msg.extend([
                    f"ğŸ’¸ èµ„é‡‘è¿½è¸ª (æ€»æµå…¥: {total_transfer:.1f} SOL)"
                ])

                # å¤„ç†æ¯æ¡èµ„é‡‘é“¾
                for i, chain in enumerate(relations['high_value_relations'], 1):
                    total_amount = sum(t['amount'] for t in chain.get('transfers', []))
                    msg.extend([
                        f"â”£â” èµ„é‡‘é“¾#{i} ({total_amount:.1f} SOL)"
                    ])
                    
                    # è®°å½•ä¸­è½¬é’±åŒ…æ•°é‡
                    transit_wallets = []
                    creator_wallets = []
                    
                    for transfer in chain.get('transfers', []):
                        timestamp = datetime.fromtimestamp(transfer['timestamp'], tz=timezone(timedelta(hours=8)))
                        wallet_label = f"(é’±åŒ…{chr(65 + len(transit_wallets) + len(creator_wallets))})"
                        
                        msg.extend([
                            f"â”ƒ   â¬†ï¸ {transfer['amount']:.1f} SOL ({timestamp.strftime('%m-%d %H:%M')}) | æ¥è‡ª: {transfer['source']} {wallet_label}"
                        ])
                        
                        if 'success_tokens' in transfer and transfer['success_tokens']:
                            token_info = [f"{t['symbol']}(${format_number(t['market_cap'])})" 
                                        for t in transfer['success_tokens']]
                            msg.append(f"â”ƒ   â””â”€ åˆ›å»ºä»£å¸å†å²: {' '.join(token_info)}")
                            creator_wallets.append(transfer['source'])
                        else:
                            msg.append(f"â”ƒ   â””â”€ ä¸­è½¬é’±åŒ…")
                            transit_wallets.append(transfer['source'])
                        msg.append("â”ƒ")

                    # æ·»åŠ èµ„é‡‘é“¾åˆ†æ
                    msg.extend([
                        "â”ƒ",
                        "â”£â” é“¾è·¯åˆ†æ:",
                        f"â”ƒ   â€¢ å‘ç°{len(creator_wallets)}ä¸ªåˆ›å»ºè€…é’±åŒ…, {len(transit_wallets)}ä¸ªä¸­è½¬é’±åŒ…",
                        f"â”ƒ   â€¢ èµ„é‡‘æµå‘: {' -> '.join([f'é’±åŒ…{chr(65+i)}' for i in range(len(transit_wallets) + len(creator_wallets) + 1)])}",
                        "â”ƒ"
                    ])

                # æ·»åŠ æ€»ä½“åˆ†æ
                success_creators = len([r for r in relations['high_value_relations'] 
                                    if any(t['market_cap'] > 10_000_000 for t in r.get('success_tokens', []))])
                total_market_cap = sum(t['market_cap'] for r in relations['high_value_relations'] 
                                    for t in r.get('success_tokens', []))
                
                msg.extend([
                    "",
                    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” ğŸ’¡ èµ„é‡‘é“¾åˆ†æ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“",
                    f"â”ƒ â€¢ è¿½è¸ªåˆ°{success_creators}ä¸ªæˆåŠŸé¡¹ç›®åˆ›å»ºè€… | èµ„é‡‘æºæ€»å¸‚å€¼: ${format_number(total_market_cap)}{' '*8}â”ƒ",
                    f"â”ƒ â€¢ å‘ç°{len(transit_wallets)}ä¸ªä¸­è½¬é’±åŒ… | æœ€æ—©èµ„é‡‘æ¥æºäº {min(t['timestamp'] for r in relations['high_value_relations'] for t in r.get('transfers', [])):%m-%d %H:%M}{' '*8}â”ƒ",
                    "â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›",
                    "",
                    "ğŸ¯ é£é™©è¯„ä¼°",
                    f"â”£â” é£é™©è¯„åˆ†: {relations['risk_score']}/100 | é£é™©ç­‰çº§: {'é«˜' if relations['risk_score'] >= 70 else 'ä¸­' if relations['risk_score'] >= 40 else 'ä½'}",
                    "â”£â” èµ„é‡‘æ¥æºæ¸…æ™°,å¯è¿½æº¯åˆ°æˆåŠŸåˆ›å»ºè€…" if creator_wallets else "â”£â” æ— æ³•è¿½è¸ªåˆ°æ˜ç¡®çš„æˆåŠŸåˆ›å»ºè€…",
                    f"â”£â” {'ä½¿ç”¨å¤šå±‚ä¸­è½¬å¢åŠ è¿½è¸ªéš¾åº¦' if len(transit_wallets) > 2 else 'èµ„é‡‘è·¯å¾„ç›¸å¯¹ç®€å•'}",
                    "â”—â” ä¸­è½¬é’±åŒ…æ— åˆ›å»ºä»£å¸å†å²"
                ])

                # ä¿®æ”¹æŠ•èµ„å»ºè®®
                msg.extend([
                    "",
                    "ğŸ’¡ æŠ•èµ„å»ºè®®",
                    "â”£â” âš ï¸ æ–°é’±åŒ…åˆ›å»º,éœ€è°¨æ…å¯¹å¾…",
                    "â”£â” ğŸŒŸ èµ„é‡‘æœ€ç»ˆæ¥æºä¸ºæˆåŠŸä»£å¸åˆ›å»ºè€…" if creator_wallets else "â”£â” âš ï¸ æ— æ˜æ˜¾æˆåŠŸé¡¹ç›®èƒŒæ™¯",
                    f"â”£â” {'âš ï¸ ä½¿ç”¨å¤šå±‚ä¸­è½¬é’±åŒ…,å¢åŠ é£é™©' if len(transit_wallets) > 2 else 'ğŸ’¡ èµ„é‡‘è·¯å¾„æ¸…æ™°'}",
                    "â”—â” â— å»ºè®®è°¨æ…è·Ÿè¸ªè§‚å¯Ÿ"
                ])

            # æ·»åŠ åˆ›å»ºè€…å†å²
            if history:
                active_tokens = sum(1 for t in history if t["status"] == "æ´»è·ƒ")
                success_rate = active_tokens / len(history) if history else 0
                msg.extend([
                    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” ğŸ“œ åˆ›å»ºè€…å†å² â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“",
                    f"â”ƒ å†å²ä»£å¸: {len(history)}ä¸ª | å½“å‰æ´»è·ƒ: {active_tokens}ä¸ª | æˆåŠŸç‡: {success_rate:.1%}{' '*20}â”ƒ",
                    "â”£â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”«"
                ])
                
                for i, token in enumerate(sorted(history, key=lambda x: x["timestamp"], reverse=True)[:3], 1):
                    timestamp = datetime.fromtimestamp(token["timestamp"], tz=timezone(timedelta(hours=8)))
                    msg.append(
                        f"â”ƒ [{i}] åˆ›å»º: {timestamp.strftime('%m-%d %H:%M')} | æœ€é«˜: ${format_number(token['max_market_cap'])} | "
                        f"å½“å‰: ${format_number(token['current_market_cap'])} | çŠ¶æ€: {token['status']}{' '*4}â”ƒ"
                    )
                msg.append("â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›")

            # æ·»åŠ åˆ†ææ€»ç»“
            if relations['high_value_relations']:
                success_creators = len([r for r in relations['high_value_relations'] 
                                    if any(t['market_cap'] > 10_000_000 for t in r.get('success_tokens', []))])
                total_market_cap = sum(t['market_cap'] for r in relations['high_value_relations'] 
                                    for t in r.get('success_tokens', []))
                msg.extend([
                    "",
                    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” ğŸ’¡ åˆ†ææ€»ç»“ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“",
                    f"â”ƒ â€¢ å‘ç°{success_creators}ä¸ªæˆåŠŸé¡¹ç›®åˆ›å»ºè€…(>$10M) | èµ„é‡‘æºæ€»å¸‚å€¼: ${format_number(total_market_cap)}{' '*12}â”ƒ",
                    f"â”ƒ â€¢ é£é™©è¯„åˆ†: {relations['risk_score']}/100 | é£é™©ç­‰çº§: {'é«˜' if relations['risk_score'] >= 70 else 'ä¸­' if relations['risk_score'] >= 40 else 'ä½'} | å…³è”åœ°å€: {len(relations['related_addresses'])}ä¸ª{' '*12}â”ƒ",
                    "â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›"
                ])

            # æ·»åŠ æŠ•èµ„å»ºè®®
            msg.extend([
                "",
                "ğŸ’¡ æŠ•èµ„å»ºè®®",
                "â”£â” âš ï¸ æ–°é’±åŒ…åˆ›å»º,éœ€è°¨æ…å¯¹å¾…" if relations['is_new_wallet'] else "â”£â” ğŸ“… è€é’±åŒ…,å†å²å¯æŸ¥",
                "â”£â” ğŸŒŸ èµ„é‡‘æ¥æºåŒ…å«å¤šä¸ªæˆåŠŸä»£å¸åˆ›å»ºè€…" if relations['high_value_relations'] else "â”£â” âš ï¸ æ— æ˜æ˜¾æˆåŠŸé¡¹ç›®èƒŒæ™¯",
                f"â”£â” ğŸ’° ä¸Šæ¸¸æœ€é«˜å¸‚å€¼é¡¹ç›®: ${format_number(max(t['market_cap'] for r in relations['high_value_relations'] for t in r.get('success_tokens', [0])))} (LUNA)",
                "â”—â” â— å»ºè®®é‡ç‚¹å…³æ³¨æ­¤é¡¹ç›®" if relations['risk_score'] < 70 and relations['high_value_relations'] else "â”—â” â— å»ºè®®è°¨æ…å¯¹å¾…"
            ])

            # æ·»åŠ å¿«é€Ÿé“¾æ¥
            msg.extend([
                "",
                "ğŸ”— å¿«é€Ÿé“¾æ¥",
                f"â”£â” Birdeye: https://birdeye.so/token/{mint}",
                f"â”£â” Solscan: https://solscan.io/token/{mint}",
                f"â”—â” åˆ›å»ºè€…: https://solscan.io/account/{creator}",
                "",
                f"â° å‘ç°æ—¶é—´: {datetime.now(tz=timezone(timedelta(hours=8))).strftime('%Y-%m-%d %H:%M:%S')} (UTC+8)"
            ])

            return "\n".join(msg)
        except Exception as e:
            logging.error(f"æ ¼å¼åŒ–è­¦æŠ¥æ¶ˆæ¯å¤±è´¥: {str(e)}")
            logging.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return "æ¶ˆæ¯æ ¼å¼åŒ–å¤±è´¥"

    def send_notification(self, msg):
        """å‘é€é€šçŸ¥"""
        # Serveré…±æ¨é€
        for key in self.config["serverchan"]["keys"]:
            try:
                response = requests.post(
                    f"https://sctapi.ftqq.com/{key}.send",
                    data={"title": "Solanaæ–°ä»£å¸æé†’", "desp": msg},
                    timeout=5
                )
                if response.status_code == 200:
                    logging.info(f"Serveré…±æ¨é€æˆåŠŸ ({key[:8]}...{key[-8:]})")
                else:
                    logging.warning(f"Serveré…±æ¨é€å¤±è´¥ ({key[:8]}...{key[-8:]}): {response.text}")
            except Exception as e:
                logging.error(f"Serveré…±æ¨é€å¤±è´¥ ({key[:8]}...{key[-8:]}): {str(e)}")
                logging.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        
        # WeChatFerryæ¨é€
        if self.wcf and self.config["wcf"]["groups"]:
            for group in self.config["wcf"]["groups"]:
                try:
                    self.wcf.send_text(group["wxid"], msg)
                    logging.info(f"WeChatFerryæ¨é€æˆåŠŸ ({group['name']})")
                except Exception as e:
                    logging.error(f"WeChatFerryæ¨é€å¤±è´¥ ({group['name']}): {str(e)}")
                    logging.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")

    def start_worker_threads(self):
        """å¯åŠ¨æ›´å¤šå·¥ä½œçº¿ç¨‹"""
        # å¯åŠ¨åŒºå—å¤„ç†çº¿ç¨‹
        for _ in range(10):
            Thread(target=self.process_blocks, daemon=True).start()
        
        # å¯åŠ¨äº¤æ˜“åˆ†æçº¿ç¨‹
        for _ in range(5):
            Thread(target=self.process_transactions, daemon=True).start()
        
        # å¯åŠ¨ç»“æœå¤„ç†çº¿ç¨‹
        for _ in range(3):
            Thread(target=self.process_results, daemon=True).start()

    def process_blocks(self):
        """å¤„ç†åŒºå—æ•°æ®"""
        while True:
            try:
                block_data = self.tx_queue.get()
                if not block_data:
                    continue
                
                block = block_data.get("result")
                if not block or "transactions" not in block:
                    continue
                
                for tx in block["transactions"]:
                    if "transaction" not in tx or "message" not in tx["transaction"]:
                        continue
                        
                    account_keys = tx["transaction"]["message"].get("accountKeys", [])
                    if self.PUMP_PROGRAM in account_keys:
                        creator = account_keys[0]
                        mint = account_keys[4]
                        self.result_queue.put((mint, creator))
                        self.metrics['processed_txs'] += 1
                    
            except Exception as e:
                logging.error(f"å¤„ç†åŒºå—å¤±è´¥: {str(e)}")
                continue

    def process_results(self):
        """å¤„ç†åˆ†æç»“æœ"""
        while True:
            try:
                result = self.result_queue.get()
                if not result:
                    continue
                
                msg = self.format_alert_message(result)
                self.send_notification(msg)
                
            except Exception as e:
                logging.error(f"å¤„ç†ç»“æœå¤±è´¥: {str(e)}")
                continue

    def monitor_metrics(self):
        """ç›‘æ§å¤„ç†æŒ‡æ ‡"""
        while True:
            try:
                now = time.time()
                duration = now - self.metrics['last_process_time']
                blocks_per_second = self.metrics['processed_blocks'] / duration if duration > 0 else 0
                txs_per_second = self.metrics['processed_txs'] / duration if duration > 0 else 0
                avg_delay = sum(self.metrics['processing_delays']) / len(self.metrics['processing_delays']) if self.metrics['processing_delays'] else 0
                
                logging.info(f"æ€§èƒ½æŒ‡æ ‡ - "
                            f"åŒºå—å¤„ç†é€Ÿåº¦: {blocks_per_second:.2f}/s, "
                            f"äº¤æ˜“å¤„ç†é€Ÿåº¦: {txs_per_second:.2f}/s, "
                            f"å¹³å‡å»¶è¿Ÿ: {avg_delay:.2f}s, "
                            f"ä¸¢å¤±åŒºå—: {len(self.metrics['missed_blocks'])}")
                
                # é‡ç½®è®¡æ•°å™¨
                self.metrics['processed_blocks'] = 0
                self.metrics['processed_txs'] = 0
                self.metrics['last_process_time'] = now
                self.metrics['processing_delays'] = []
                
                # å°è¯•é‡æ–°å¤„ç†ä¸¢å¤±çš„åŒºå—
                if self.metrics['missed_blocks']:
                    self.retry_missed_blocks()
                
                time.sleep(60)  # æ¯åˆ†é’Ÿè¾“å‡ºä¸€æ¬¡æŒ‡æ ‡
                
            except Exception as e:
                logging.error(f"ç›‘æ§æŒ‡æ ‡é”™è¯¯: {str(e)}")
                time.sleep(60)

    def retry_missed_blocks(self):
        """é‡è¯•å¤„ç†ä¸¢å¤±çš„åŒºå—"""
        if not self.metrics['missed_blocks']:
            return
        
        logging.info(f"å¼€å§‹é‡è¯•å¤„ç† {len(self.metrics['missed_blocks'])} ä¸ªä¸¢å¤±åŒºå—")
        
        retry_slots = list(self.metrics['missed_blocks'])
        self.metrics['missed_blocks'].clear()
        
        with ThreadPoolExecutor(max_workers=self.parallel_requests) as executor:
            futures = []
            for slot in retry_slots:
                future = executor.submit(
                    self.parallel_rpc_request,
                    "getBlock",
                    [slot, {"encoding":"json","transactionDetails":"full"}]
                )
                futures.append((slot, future))
            
            for slot, future in futures:
                try:
                    response = future.result()
                    if response and response.status_code == 200:
                        self.tx_queue.put(response.json())
                    else:
                        self.metrics['missed_blocks'].add(slot)
                except Exception as e:
                    self.metrics['missed_blocks'].add(slot)
                    logging.error(f"é‡è¯•åŒºå— {slot} å¤±è´¥: {str(e)}")

    def monitor(self):
        """ä¸»ç›‘æ§å‡½æ•°"""
        logging.info("ç›‘æ§å¯åŠ¨...")
        last_slot = 0
        self.PUMP_PROGRAM = "6EF8rrecthR5Dkzon8Nwu78hRvfCKubJ35MKDfgCcMKJ"
        
        while True:
            try:
                start_time = time.time()
                
                # å¹¶è¡Œè¯·æ±‚è·å–å½“å‰slot
                response = self.parallel_rpc_request("getSlot")
                if not response:
                    continue
                    
                current_slot = response.json()["result"]
                slots_to_process = range(last_slot + 1, current_slot + 1)
                
                # åˆ†æ‰¹å¤„ç†åŒºå—
                for batch_start in range(0, len(slots_to_process), self.block_batch_size):
                    batch_slots = slots_to_process[batch_start:batch_start + self.block_batch_size]
                    
                    # å¹¶è¡Œå¤„ç†ä¸€æ‰¹åŒºå—
                    with ThreadPoolExecutor(max_workers=self.parallel_requests) as executor:
                        futures = []
                        for slot in batch_slots:
                            future = executor.submit(
                                self.parallel_rpc_request,
                                "getBlock",
                                [slot, {"encoding":"json","transactionDetails":"full"}]
                            )
                            futures.append((slot, future))
                        
                        # ä½¿ç”¨as_completedå¿«é€Ÿå¤„ç†ç»“æœ
                        for slot, future in futures:
                            try:
                                response = future.result()
                                if response and response.status_code == 200:
                                    self.tx_queue.put(response.json())
                                    self.metrics['processed_blocks'] += 1
                                else:
                                    self.metrics['missed_blocks'].add(slot)
                            except Exception as e:
                                self.metrics['missed_blocks'].add(slot)
                                logging.error(f"å¤„ç†åŒºå— {slot} å¤±è´¥: {str(e)}")
                
                # è®°å½•å¤„ç†å»¶è¿Ÿ
                process_time = time.time() - start_time
                self.metrics['processing_delays'].append(process_time)
                
                last_slot = current_slot
                time.sleep(0.02)  # å‡å°‘è½®è¯¢é—´éš”åˆ°20ms
                
            except Exception as e:
                logging.error(f"ç›‘æ§å¾ªç¯é”™è¯¯: {str(e)}")
                time.sleep(1)

    def set_proxy(self, ip, port, username, password):
        """è®¾ç½®ä»£ç†é…ç½®"""
        try:
            self.proxy_config.update({
                'ip': ip,
                'port': port,
                'username': username,
                'password': password,
                'enabled': True
            })
            
            # ä¿å­˜åˆ°é…ç½®æ–‡ä»¶
            self.config['proxy'] = self.proxy_config
            with open(self.config_file, 'w') as f:
                json.dump(self.config, f, indent=2)
                
            # æµ‹è¯•ä»£ç†è¿æ¥
            if self.test_proxy():
                logging.info("ä»£ç†è®¾ç½®æˆåŠŸå¹¶å·²éªŒè¯")
                return True
            else:
                self.proxy_config['enabled'] = False
                logging.error("ä»£ç†è®¾ç½®å¤±è´¥ï¼Œå·²ç¦ç”¨ä»£ç†")
                return False
                
        except Exception as e:
            logging.error(f"è®¾ç½®ä»£ç†å¤±è´¥: {str(e)}")
            return False

    def get_proxy_url(self):
        """è·å–ä»£ç†URL"""
        if not self.proxy_config['enabled']:
            return None
            
        config = self.proxy_config
        if not all([config['ip'], config['port'], config['username'], config['password']]):
            return None
            
        return f"http://{config['username']}:{config['password']}@{config['ip']}:{config['port']}"

    def get_proxies(self):
        """è·å–ä»£ç†é…ç½®"""
        # å¦‚æœä»£ç†æœªå¯ç”¨ï¼Œç›´æ¥è¿”å› None (ä½¿ç”¨æœ¬æœºç½‘ç»œ)
        if not self.proxy_config['enabled']:
            return None
        
        # æ£€æŸ¥å¿…è¦çš„ä»£ç†é…ç½®æ˜¯å¦å®Œæ•´
        if not all([self.proxy_config['ip'], 
                    self.proxy_config['port'], 
                    self.proxy_config['username'], 
                    self.proxy_config['password']]):
            logging.warning("ä»£ç†é…ç½®ä¸å®Œæ•´ï¼Œä½¿ç”¨æœ¬æœºç½‘ç»œ")
            return None
        
        # æ„å»ºä»£ç†URL
        proxy_url = f"http://{self.proxy_config['username']}:{self.proxy_config['password']}@{self.proxy_config['ip']}:{self.proxy_config['port']}"
        
        return {
            "http": proxy_url,
            "https": proxy_url
        }

    def test_proxy(self):
        """æµ‹è¯•ä»£ç†è¿æ¥"""
        try:
            proxies = self.get_proxies()
            if not proxies:
                logging.info("æœªé…ç½®ä»£ç†æˆ–ä»£ç†æœªå¯ç”¨")
                return False
            
            test_url = 'https://api.mainnet-beta.solana.com'
            response = requests.get(
                test_url,
                proxies=proxies,
                timeout=5,
                verify=False
            )
            
            if response.status_code == 200:
                logging.info("ä»£ç†è¿æ¥æµ‹è¯•æˆåŠŸ")
                return True
            else:
                logging.warning(f"ä»£ç†è¿æ¥æµ‹è¯•å¤±è´¥: HTTP {response.status_code}")
                return False
            
        except requests.exceptions.ProxyError as e:
            logging.error(f"ä»£ç†è¿æ¥é”™è¯¯: {str(e)}")
            return False
        except Exception as e:
            logging.error(f"ä»£ç†æµ‹è¯•å¤±è´¥: {str(e)}")
            return False

    def make_request(self, url, headers=None, timeout=10):
        """å‘é€HTTPè¯·æ±‚ï¼ˆå¸¦ä»£ç†æ”¯æŒï¼‰"""
        try:
            proxies = self.get_proxies()
            if proxies:
                logging.debug(f"ä½¿ç”¨ä»£ç†å‘é€è¯·æ±‚: {url}")
            else:
                logging.debug(f"ä½¿ç”¨æœ¬æœºç½‘ç»œå‘é€è¯·æ±‚: {url}")
            
            response = requests.get(
                url,
                headers=headers,
                proxies=proxies,
                timeout=timeout,
                verify=False  # å¦‚æœä»£ç†æœ‰è¯ä¹¦é—®é¢˜ï¼Œå¯ä»¥ç¦ç”¨éªŒè¯
            )
            return response
            
        except requests.exceptions.ProxyError as e:
            logging.error(f"ä»£ç†è¿æ¥é”™è¯¯: {str(e)}")
            # ä»£ç†å¤±è´¥æ—¶è‡ªåŠ¨åˆ‡æ¢åˆ°æœ¬æœºç½‘ç»œ
            logging.info("è‡ªåŠ¨åˆ‡æ¢åˆ°æœ¬æœºç½‘ç»œé‡è¯•")
            return requests.get(url, headers=headers, timeout=timeout)
        except Exception as e:
            logging.error(f"è¯·æ±‚å¤±è´¥: {str(e)}")
            return None

    def trace_fund_flow(self, address, depth=0, max_depth=5, visited=None, chain=None):
        """è¿½è¸ªèµ„é‡‘æ¥æºï¼Œæœ€å¤šè¿½è¸ª5å±‚"""
        if visited is None:
            visited = set()
        if chain is None:
            chain = []
        if depth >= max_depth or address in visited:
            return []
        
        visited.add(address)
        chains = []
        
        try:
            # è·å–åœ°å€çš„è½¬å…¥äº¤æ˜“
            api_key = self.get_next_api_key()
            url = f"https://public-api.birdeye.so/public/address_activity?address={address}"
            response = requests.get(url, headers={"X-API-KEY": api_key})
            if response.status_code != 200:
                return []
                
            data = response.json()
            if not data.get("success"):
                return []
                
            transactions = data.get("data", {}).get("items", [])
            
            # åˆ†æè½¬å…¥äº¤æ˜“
            for tx in transactions:
                if tx.get("amount", 0) < 1:  # å¿½ç•¥å°äº1 SOLçš„è½¬è´¦
                    continue
                    
                source_address = tx.get("source")
                if not source_address or source_address in visited:
                    continue
                
                # è®°å½•å½“å‰è½¬è´¦ä¿¡æ¯
                transfer_info = {
                    "source": source_address,
                    "amount": tx.get("amount", 0),
                    "timestamp": tx.get("timestamp", 0),
                    "tx_id": tx.get("signature")
                }
                
                # æ£€æŸ¥æºåœ°å€æ˜¯å¦åˆ›å»ºè¿‡æˆåŠŸçš„ä»£å¸
                success_tokens = self.check_address_success_tokens(source_address)
                if success_tokens:
                    transfer_info["success_tokens"] = success_tokens
                
                new_chain = chain + [transfer_info]
                
                # å¦‚æœæ‰¾åˆ°æˆåŠŸä»£å¸åˆ›å»ºè€…ï¼Œè®°å½•æ•´æ¡é“¾
                if success_tokens:
                    chains.append(new_chain)
                
                # ç»§ç»­è¿½è¸ªä¸Šå±‚èµ„é‡‘æ¥æº
                sub_chains = self.trace_fund_flow(source_address, depth + 1, max_depth, visited.copy(), new_chain)
                chains.extend(sub_chains)
            
            return chains
            
        except Exception as e:
            logging.error(f"è¿½è¸ªèµ„é‡‘æµå‘å¤±è´¥: {str(e)}")
            logging.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return []

    def check_address_success_tokens(self, address):
        """æ£€æŸ¥åœ°å€æ˜¯å¦åˆ›å»ºè¿‡æˆåŠŸçš„ä»£å¸ï¼ˆå¸‚å€¼è¶…è¿‡1000ä¸‡ï¼‰"""
        try:
            api_key = self.get_next_api_key()
            url = f"https://public-api.birdeye.so/public/token_list?creator={address}"
            response = requests.get(url, headers={"X-API-KEY": api_key})
            if response.status_code != 200:
                return []
                
            data = response.json()
            if not data.get("success"):
                return []
                
            success_tokens = []
            for token in data.get("data", {}).get("items", []):
                market_cap = token.get("marketCap", 0)
                if market_cap >= 10_000_000:  # å¸‚å€¼è¶…è¿‡1000ä¸‡
                    success_tokens.append({
                        "address": token.get("address"),
                        "symbol": token.get("symbol"),
                        "name": token.get("name"),
                        "market_cap": market_cap,
                        "created_at": token.get("createdAt")
                    })
            
            return success_tokens
            
        except Exception as e:
            logging.error(f"æ£€æŸ¥åœ°å€æˆåŠŸä»£å¸å¤±è´¥: {str(e)}")
            logging.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return []

    def get_cached_data(self, cache_type, key):
        """è·å–ç¼“å­˜æ•°æ®"""
        if key in self.cache[cache_type]:
            data, timestamp = self.cache[cache_type][key]
            if time.time() - timestamp < self.cache_expire[cache_type]:
                return data
        return None

    def set_cached_data(self, cache_type, key, data):
        """è®¾ç½®ç¼“å­˜æ•°æ®"""
        self.cache[cache_type][key] = (data, time.time())

    def analyze_token(self, mint, creator):
        """å¹¶è¡Œåˆ†æä»£å¸ä¿¡æ¯"""
        try:
            with ThreadPoolExecutor(max_workers=3) as executor:
                futures = {
                    'token_info': executor.submit(self.fetch_token_info, mint),
                    'creator_history': executor.submit(self.analyze_creator_history, creator),
                    'fund_flow': executor.submit(self.trace_fund_flow, creator)
                }
                
                results = {
                    key: future.result() for key, future in futures.items()
                }
                
                return results
        except Exception as e:
            logging.error(f"åˆ†æä»£å¸å¤±è´¥: {str(e)}")
            return None

    def fetch_token_info(self, mint):
        """æ‰¹é‡è·å–ä»£å¸ä¿¡æ¯"""
        cached = self.get_cached_data('token_info', mint)
        if cached:
            return cached
        
        try:
            headers = {"X-API-KEY": self.get_next_api_key()}
            params = {
                "address": mint,
                "get_metadata": 1,
                "get_holders": 1,
                "get_price": 1
            }
            
            response = self.make_request(
                "https://public-api.birdeye.so/public/multi_tokens",
                headers=headers,
                params=params
            )
            
            if response and response.status_code == 200:
                data = response.json()
                self.set_cached_data('token_info', mint, data)
                return data
            
        except Exception as e:
            logging.error(f"è·å–ä»£å¸ä¿¡æ¯å¤±è´¥: {str(e)}")
        return None

    def process_transactions(self):
        """å¤„ç†äº¤æ˜“é˜Ÿåˆ—"""
        while True:
            try:
                tx_data = self.tx_queue.get()
                if tx_data is None:
                    break
                    
                mint, creator = tx_data
                results = self.analyze_token(mint, creator)
                
                if results and self.should_notify(results):
                    msg = self.format_alert_message(results)
                    self.send_notification(msg)
                    
            except Exception as e:
                logging.error(f"å¤„ç†äº¤æ˜“å¤±è´¥: {str(e)}")
                continue

if __name__ == "__main__":
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('solana_monitor.log')
        ]
    )
    
    monitor = TokenMonitor()

    def test_fund_tracking():
        """æµ‹è¯•èµ„é‡‘è¿½è¸ªåŠŸèƒ½"""
        print("\næµ‹è¯•èµ„é‡‘è¿½è¸ªåŠŸèƒ½...")
        # æ¨¡æ‹Ÿä¸€ä¸ªæ–°ä»£å¸åˆ›å»ºè€…åœ°å€
        creator = "7KwQSUqvHFUJVZpBxu1bGgUoUJvYxGgHqxgAJpKqpKpj"
        
        print(f"è¿½è¸ªåœ°å€: {creator}")
        funding_chains = monitor.trace_fund_flow(creator)
        
        if funding_chains:
            print(f"\nå‘ç° {len(funding_chains)} æ¡èµ„é‡‘é“¾:")
            for i, chain in enumerate(funding_chains, 1):
                print(f"\né“¾è·¯ {i}:")
                total_amount = sum(t['amount'] for t in chain)
                print(f"æ€»è½¬è´¦é‡‘é¢: {total_amount:.2f} SOL")
                print(f"é“¾è·¯æ·±åº¦: {len(chain)} å±‚")
                
                # æ˜¾ç¤ºæ¯å±‚è½¬è´¦è¯¦æƒ…
                for j, transfer in enumerate(chain, 1):
                    time_str = datetime.fromtimestamp(
                        transfer["timestamp"], 
                        tz=timezone(timedelta(hours=8))
                    ).strftime('%Y-%m-%d %H:%M')
                    print(f"  [{j}/{len(chain)}] {time_str} | {transfer['amount']:.2f} SOL")
                    print(f"      {transfer['source']} ->")
                    
                    # å¦‚æœæœ‰æˆåŠŸä»£å¸å†å²ï¼Œæ˜¾ç¤ºè¯¦æƒ…
                    if "success_tokens" in transfer:
                        for token in transfer["success_tokens"]:
                            print(f"      å†å²ä»£å¸: {token['symbol']} (${format_number(token['market_cap'])})")
        else:
            print("æœªå‘ç°èµ„é‡‘é“¾")

    def test_token_info():
        """æµ‹è¯•ä»£å¸ä¿¡æ¯è·å–"""
        print("\næµ‹è¯•ä»£å¸ä¿¡æ¯è·å–...")
        # æ¨¡æ‹Ÿä¸€ä¸ªä»£å¸åœ°å€
        mint = "7xKXtg2CW87d97TXJSDpbD5jBkheTqA83TZRuJosgAsU"
        
        print(f"è·å–ä»£å¸ä¿¡æ¯: {mint}")
        token_info = monitor.fetch_token_info(mint)
        
        print("\nä»£å¸è¯¦æƒ…:")
        print(f"åç§°: {token_info['name']}")
        print(f"ç¬¦å·: {token_info['symbol']}")
        print(f"å¸‚å€¼: ${format_number(token_info['market_cap'])}")
        print(f"æµåŠ¨æ€§: {token_info['liquidity']:.2f} SOL")
        print(f"æŒæœ‰äººæ•°é‡: {token_info['holder_count']}")
        print(f"æŒæœ‰äººé›†ä¸­åº¦: {token_info['holder_concentration']:.2f}%")

    def test_alert_message():
        """æµ‹è¯•è­¦æŠ¥æ¶ˆæ¯æ ¼å¼åŒ–"""
        print("\næµ‹è¯•è­¦æŠ¥æ¶ˆæ¯æ ¼å¼åŒ–...")
        # æ¨¡æ‹Ÿä»£å¸ä¿¡æ¯
        token_info = {
            "address": "7xKXtg2CW87d97TXJSDpbD5jBkheTqA83TZRuJosgAsU",
            "creator": "7KwQSUqvHFUJVZpBxu1bGgUoUJvYxGgHqxgAJpKqpKpj",
            "initial_market_cap": 156000,
            "liquidity": 35.5
        }
        
        # æ¨¡æ‹Ÿèµ„é‡‘é“¾
        funding_chains = [
            [
                {
                    "source": "8bxeZ2V1RjwgFBQeEKg8nkGqJ1Qo98vd6wHNxEQXKScN",
                    "amount": 8.2,
                    "timestamp": int(time.time()) - 3600,
                    "success_tokens": [
                        {
                            "symbol": "TEST",
                            "market_cap": 15000000,
                            "name": "Test Token"
                        }
                    ]
                }
            ]
        ]
        
        alert_msg = monitor.format_alert_message(token_info, funding_chains)
        print("\næ ¼å¼åŒ–æ¶ˆæ¯:")
        print(alert_msg)

    while True:
        print("\n==== Solana Token Monitor ====")
        print("1. å¯åŠ¨ç›‘æ§")
        print("2. è®¾ç½®ä»£ç†")
        print("3. æµ‹è¯•ä»£ç†è¿æ¥")
        print("4. æŸ¥çœ‹å½“å‰é…ç½®")
        print("5. æŸ¥çœ‹è¿è¡Œæ—¥å¿—")
        print("6. æµ‹è¯•èµ„é‡‘è¿½è¸ª")
        print("7. æµ‹è¯•ä»£å¸ä¿¡æ¯")
        print("8. æµ‹è¯•è­¦æŠ¥æ¶ˆæ¯")
        print("0. é€€å‡ºç¨‹åº")
        
        choice = input("\nè¯·é€‰æ‹©æ“ä½œ (0-8): ")
        
        if choice == '1':
            print("\nå¼€å§‹ç›‘æ§...")
            try:
                monitor.monitor()
            except Exception as e:
                logging.error(f"ç›‘æ§å¼‚å¸¸: {str(e)}")
                logging.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        elif choice == '2':
            print("\nè®¾ç½®ä»£ç†:")
            ip = input("ä»£ç†IP: ")
            port = input("ä»£ç†ç«¯å£: ")
            username = input("ç”¨æˆ·å: ")
            password = input("å¯†ç : ")
            if monitor.set_proxy(ip, port, username, password):
                print("ä»£ç†è®¾ç½®æˆåŠŸ")
            else:
                print("ä»£ç†è®¾ç½®å¤±è´¥")
        elif choice == '3':
            print("\næµ‹è¯•ä»£ç†è¿æ¥...")
            if monitor.test_proxy():
                print("ä»£ç†è¿æ¥æ­£å¸¸")
            else:
                print("ä»£ç†è¿æ¥å¤±è´¥")
        elif choice == '4':
            print("\nå½“å‰é…ç½®:")
            proxy_config = monitor.proxy_config
            if proxy_config['enabled']:
                print(f"ä»£ç†çŠ¶æ€: å·²å¯ç”¨")
                print(f"ä»£ç†IP: {proxy_config['ip']}")
                print(f"ä»£ç†ç«¯å£: {proxy_config['port']}")
                print(f"ä»£ç†ç”¨æˆ·å: {proxy_config['username']}")
                print(f"ä»£ç†å¯†ç : {'*' * len(proxy_config['password'])}")
            else:
                print("ä»£ç†çŠ¶æ€: æœªå¯ç”¨")
        elif choice == '5':
            print("\næœ€è¿‘çš„è¿è¡Œæ—¥å¿—:")
            try:
                with open('solana_monitor.log', 'r') as f:
                    # è¯»å–æœ€å100è¡Œ
                    lines = f.readlines()[-100:]
                    print(''.join(lines))
            except Exception as e:
                print(f"è¯»å–æ—¥å¿—å¤±è´¥: {str(e)}")
        elif choice == '6':
            test_fund_tracking()
        elif choice == '7':
            test_token_info()
        elif choice == '8':
            test_alert_message()
        elif choice == '0':
            print("\né€€å‡ºç¨‹åº...")
            break
        else:
            print("\næ— æ•ˆçš„é€‰æ‹©ï¼Œè¯·é‡è¯•")
